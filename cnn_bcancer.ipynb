{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10564,"sourceType":"datasetVersion","datasetId":7415}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nadapted form 95% accurate cifar10cnn model\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\n","metadata":{"_uuid":"f662ed74-b157-4b07-94b9-6afb6cc30ade","_cell_guid":"16c6cea9-b788-4531-b629-9f92852251c8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-26T23:15:50.942201Z","iopub.execute_input":"2024-01-26T23:15:50.942581Z","iopub.status.idle":"2024-01-26T23:15:55.589902Z","shell.execute_reply.started":"2024-01-26T23:15:50.942551Z","shell.execute_reply":"2024-01-26T23:15:55.588626Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Hyper-parameters \nepoch_count=25\nbatch_size=32\n\n# for training:\nlearning_rate = 0.001\nmomentum = 0.9\n\ntorch.manual_seed(143)\nval_size = 1000","metadata":{"execution":{"iopub.status.busy":"2024-01-26T23:16:42.279699Z","iopub.execute_input":"2024-01-26T23:16:42.280231Z","iopub.status.idle":"2024-01-26T23:16:42.292627Z","shell.execute_reply.started":"2024-01-26T23:16:42.280198Z","shell.execute_reply":"2024-01-26T23:16:42.291276Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntfs=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-26T23:18:45.146792Z","iopub.execute_input":"2024-01-26T23:18:45.147253Z","iopub.status.idle":"2024-01-26T23:18:45.153908Z","shell.execute_reply.started":"2024-01-26T23:18:45.147216Z","shell.execute_reply":"2024-01-26T23:18:45.152698Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/breast-histopathology-images/**/*.png'\ndataset=glob.glob(path,recursive=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T23:19:01.945898Z","iopub.execute_input":"2024-01-26T23:19:01.946366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-26T23:18:56.410129Z","iopub.execute_input":"2024-01-26T23:18:56.410580Z","iopub.status.idle":"2024-01-26T23:18:56.418762Z","shell.execute_reply.started":"2024-01-26T23:18:56.410546Z","shell.execute_reply":"2024-01-26T23:18:56.417732Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"print(len(train_set))\nprint(len(test_set))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#datasplit\ntrain_size = len(train_set) - val_size\ntrain_data, val_data = torch.utils.data.random_split(train_set, [train_size, val_size])\n\nids=torch.randperm(len(train_set))\n\nsplit=1000\ntr_ids,val_ids=ids[split:],ids[:split]\n\ntr_sampler=SubsetRandomSampler(tr_ids)\nval_sampler=SubsetRandomSampler(val_ids)\n\n\n#Dataloaders\ntrain_loader = DataLoader(train_set, batch_size, pin_memory=True,sampler=tr_sampler)\nval_loader = DataLoader(train_set, batch_size*2,pin_memory=True,sampler=val_sampler)\ntest_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False,pin_memory=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ImgClassifier(nn.Module):\n  def __init__(self):\n      super(ImgClassifier, self).__init__()\n      self.conv1 = nn.Conv2d(3,32,3)\n      self.conv2 = nn.Conv2d(32,32,3)\n    \n      self.pool1 = nn.MaxPool2d(2)\n      self.dout1 = nn.Dropout(0.5)\n      self.conv3 = nn.Conv2d(32,64,3)\n      self.conv4 = nn.Conv2d(64,64,3)\n\n      self.pool2 = nn.MaxPool2d(2)\n      self.dout2 = nn.Dropout(0.5)\n      self.fc=nn.Linear(64*5*5,512)\n      self.out=nn.Linear(512,10)\n\n  def forward(self, x):\n \n      x= self.conv1(x)\n      x=F.relu(x)\n\n      x= self.conv2(x)\n      x=F.relu(x)\n\n      x=self.pool1(x)\n      x=self.dout1(x)\n\n      x= self.conv3(x)\n      x=F.relu(x)\n\n      x= self.conv4(x)\n      x=F.relu(x)\n\n      x=self.pool2(x)\n      x=self.dout2(x)\n      #flatten all dimension except batch size\n      x=torch.flatten(x,1)\n\n      x = self.fc(x)\n      x=F.relu(x)\n      x=self.out(x)\n      output=F.log_softmax(x)\n\n      return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  \nmodel=ImgClassifier()\nmodel = model.to(device)  # put all model params on GPU.\n\n# Create loss and optimizer\nloss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, momentum=momentum)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#variables for tracking the losses and accuracies\nfoo1=[]#train_loss\nfoo2=[]#train_accuracy\nfoo3=[]#valid_loss\nfoo4=[]#valid_accuracy\nbestmodel={'epoch':  0,\n        'model_state_dict': model.state_dict(),\n        'loss':   0,\n        'accuracy':  0\n        }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1,epoch_count+1):\n    running_loss=0.0\n    running_total = 0\n    running_correct = 0\n    run_step = 0\n   \n    for i, (images, labels) in enumerate(train_loader):\n        model.train()  \n        \n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)  \n        loss = loss_fn(outputs, labels)\n        \n        optimizer.zero_grad()  # reset gradients.\n        loss.backward()  # compute gradients.\n        optimizer.step()  # update parameters.\n\n        running_loss += loss.item()\n        running_total += labels.size(0)\n\n        with torch.no_grad():\n            _, predicted = outputs.max(1)\n        running_correct += (predicted == labels).sum().item()\n        run_step += 1\n        if i %  500== 0:\n            # check accuracy.\n            print(f'epoch: {epoch}, steps: {i}, '\n                  f'train_loss: {running_loss / run_step :.3f}, '\n                  f'running_acc: {100 * running_correct / running_total:.1f} %')\n            foo1.append(running_loss/run_step)\n            foo2.append(100 * running_correct / running_total)\n            running_loss = 0.0\n            running_total = 0\n            running_correct = 0\n            run_step = 0\n\n    # validation\n    best_val_acc=[0,0]\n    correct = 0\n    val_loss=0\n    total = 0\n    counter=0\n    model.eval()\n    \n    with torch.no_grad():\n        for data in val_loader:\n            counter+=1\n            images,labels=data\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            val_loss += loss_fn(outputs,labels).item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            val_acc = 100 * correct / total\n\n    if 100 * correct / total >= bestmodel['accuracy']: \n      bestmodel={'epoch':  epoch,\n        'model_state_dict': model.state_dict(),\n        'loss':   val_loss,\n        'accuracy':   val_acc\n        }\n    print(f'Validation accuracy: {100 * correct / total: .3f}%   ,'\n              f'Validation loss:{val_loss/counter:.3f}')\n    foo3.append(val_loss/counter)\n    foo4.append(100 * correct / total)\n\nprint('Finished Training')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lastmodel={'epoch':  epoch_count,\n        'model_state_dict': model.state_dict(),\n        'loss':   val_loss,\n        'accuracy':   val_acc\n        }\n\ntorch.save(lastmodel,'lastmodel.pth')\ntorch.save(bestmodel,'bestmodel.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#evaluation\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    model.eval() \n    for data in test_loader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n\n        outputs=model(images)\n        _, predicted = outputs.max(dim=1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    test_acc = 100 * correct / total\n    print(f'Test accuracy: {test_acc} %')\n    print(f'Test error rate: {100 - 100 * correct / total: .2f} %')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting the losses and accuracies\nx=np.linspace(0,epoch_count,epoch_count*4)\nx1=np.arange(0,epoch_count)\n\nplt.figure(figsize=(10,7))\nplt.plot(\n    x,foo1,'g-',label='training loss'\n)\nplt.plot(\n    x1,foo3,'b-',label='validation loss'\n)\nplt.xlabel(\"Epoch count\")\nplt.ylabel(\"Magnitude\")\nplt.title(\"Training and Validation Losses\")\nplt.legend()\nplt.savefig('val_train_loss.png',dpi=300)\nplt.show()\n\nplt.figure(figsize=(10,7))\nplt.plot(\n    x,foo2,'r-',label='training accuracy'\n)\nplt.plot(\n    x1,foo4,'b-',label='validation accuracy'\n)\nplt.xlabel(\"Epoch count\")\nplt.ylabel(\"Magnitude\")\nplt.title(\"Training and Validation Accuracy\")\nplt.legend()\nplt.savefig('val_train_acccuracy.png',dpi=300)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}